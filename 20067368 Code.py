# -*- coding: utf-8 -*-
"""Untitled39.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NmCAg1EQA0l57qNMmujgp-Eyla79Noon
"""

# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report

# Load the Dinosaur List dataset
dinosaur_df = pd.read_csv('dinosaur.csv')

# Display the first few rows of the dataset
print("First few rows of the dataset:")
print(dinosaur_df.head())

# Preprocessing the data
# One-hot encode categorical features
one_hot_encoder = OneHotEncoder()
encoded_features = one_hot_encoder.fit_transform(dinosaur_df[['Period', 'Diet', 'Country']]).toarray()

# Concatenate encoded features with numerical features
encoded_df = pd.concat([dinosaur_df.drop(['Period', 'Diet', 'Country'], axis=1), pd.DataFrame(encoded_features)], axis=1)

# Splitting the data into features (X) and target (y)
X = encoded_df.drop('Name', axis=1)
y = encoded_df['Name']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Naive Bayes Classifier
nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)

# Evaluation
print("\nNaive Bayes Classifier:")
nb_predictions = nb_classifier.predict(X_test)
print(classification_report(y_test, nb_predictions))

import matplotlib.pyplot as plt
import seaborn as sns

# Example precision, recall, and F1-score values
precision = [0.82, 0.75, 0.90, 0.80, 0.88]  # Example precision values for 5 classes
recall = [0.85, 0.70, 0.92, 0.78, 0.85]  # Example recall values for 5 classes
f1_score = [0.83, 0.72, 0.91, 0.79, 0.86]  # Example F1-score values for 5 classes
labels = ['Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']  # Example class labels

# Plotting
plt.figure(figsize=(10, 6))
sns.barplot(x=labels, y=precision, color='blue', alpha=0.7, label='Precision')
sns.barplot(x=labels, y=recall, color='green', alpha=0.7, label='Recall')
sns.barplot(x=labels, y=f1_score, color='red', alpha=0.7, label='F1-score')
plt.title('Naive Bayes Classifier Performance')
plt.xlabel('Class')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.legend(loc='upper right')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Example precision, recall, and F1-score values for Decision Tree Classifier
dt_precision = [0.78, 0.82, 0.85, 0.76, 0.79]  # Example precision values for 5 classes
dt_recall = [0.82, 0.75, 0.80, 0.85, 0.78]  # Example recall values for 5 classes
dt_f1_score = [0.80, 0.78, 0.82, 0.80, 0.80]  # Example F1-score values for 5 classes

# Example precision, recall, and F1-score values for Random Forests
rf_precision = [0.85, 0.88, 0.90, 0.82, 0.86]  # Example precision values for 5 classes
rf_recall = [0.88, 0.82, 0.85, 0.90, 0.88]  # Example recall values for 5 classes
rf_f1_score = [0.86, 0.85, 0.87, 0.86, 0.87]  # Example F1-score values for 5 classes

labels = ['Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']  # Example class labels

# Plotting for Decision Tree Classifier
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.barplot(x=labels, y=dt_precision, color='blue', alpha=0.7, label='Precision')
sns.barplot(x=labels, y=dt_recall, color='green', alpha=0.7, label='Recall')
sns.barplot(x=labels, y=dt_f1_score, color='red', alpha=0.7, label='F1-score')
plt.title('Decision Tree Classifier Performance')
plt.xlabel('Class')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.legend(loc='upper right')

# Plotting for Random Forests
plt.subplot(1, 2, 2)
sns.barplot(x=labels, y=rf_precision, color='blue', alpha=0.7, label='Precision')
sns.barplot(x=labels, y=rf_recall, color='green', alpha=0.7, label='Recall')
sns.barplot(x=labels, y=rf_f1_score, color='red', alpha=0.7, label='F1-score')
plt.title('Random Forests Performance')
plt.xlabel('Class')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.legend(loc='upper right')

plt.tight_layout()
plt.show()